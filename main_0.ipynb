{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import cv2\n",
    "from skimage import io\n",
    "from scenedetect import detect, AdaptiveDetector\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "avengers_path = \"D:/iiitd/sem_1/ML/Project/VideoCompressionDataset/AvengersEndgme.mkv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\iiitd\\sem_1\\ML\\Project\\main_0.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/iiitd/sem_1/ML/Project/main_0.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m scene_list \u001b[39m=\u001b[39m detect(avengers_path, AdaptiveDetector())\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\scenedetect\\__init__.py:156\u001b[0m, in \u001b[0;36mdetect\u001b[1;34m(video_path, detector, stats_file_path, show_progress, start_time, end_time, start_in_scene)\u001b[0m\n\u001b[0;32m    154\u001b[0m scene_manager \u001b[39m=\u001b[39m SceneManager(StatsManager() \u001b[39mif\u001b[39;00m stats_file_path \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    155\u001b[0m scene_manager\u001b[39m.\u001b[39madd_detector(detector)\n\u001b[1;32m--> 156\u001b[0m scene_manager\u001b[39m.\u001b[39;49mdetect_scenes(\n\u001b[0;32m    157\u001b[0m     video\u001b[39m=\u001b[39;49mvideo,\n\u001b[0;32m    158\u001b[0m     show_progress\u001b[39m=\u001b[39;49mshow_progress,\n\u001b[0;32m    159\u001b[0m     end_time\u001b[39m=\u001b[39;49mend_time,\n\u001b[0;32m    160\u001b[0m )\n\u001b[0;32m    161\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m scene_manager\u001b[39m.\u001b[39mstats_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     scene_manager\u001b[39m.\u001b[39mstats_manager\u001b[39m.\u001b[39msave_to_csv(csv_file\u001b[39m=\u001b[39mstats_file_path)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\scenedetect\\scene_manager.py:882\u001b[0m, in \u001b[0;36mSceneManager.detect_scenes\u001b[1;34m(self, video, duration, end_time, frame_skip, show_progress, callback, frame_source)\u001b[0m\n\u001b[0;32m    880\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mDetecting scenes...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    881\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop\u001b[39m.\u001b[39mis_set():\n\u001b[1;32m--> 882\u001b[0m     next_frame, position \u001b[39m=\u001b[39m frame_queue\u001b[39m.\u001b[39;49mget()\n\u001b[0;32m    883\u001b[0m     \u001b[39mif\u001b[39;00m next_frame \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m position \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[1;32m--> 171\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait()\n\u001b[0;32m    172\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be a non-negative number\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scene_list = detect(avengers_path, AdaptiveDetector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = []\n",
    "for (i, j) in scene_list:\n",
    "    arr.append(i.get_frames() + 1)\n",
    "    \n",
    "len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame(image):\n",
    "    r, c, d = image.shape\n",
    "    image = image.reshape(r * c, d)\n",
    "    kmeans = KMeans(n_clusters=32, n_init=1, max_iter=200)\n",
    "    kmeans.fit(image)\n",
    "\n",
    "    clusters = np.asarray(kmeans.cluster_centers_, dtype=np.uint8)\n",
    "    labels = np.asarray(kmeans.labels_, dtype=np.uint8)\n",
    "    labels = labels.reshape(r, c)\n",
    "    \n",
    "    return clusters[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 13, 114, 140, 142, 204, 206, 255, 258, 409, 411, 604, 606, 613, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 695, 696, 704, 728, 754, 755, 756, 757, 758, 759, 774, 803, 805, 806, 845, 846, 851, 865, 866, 867, 868, 869, 877, 878, 879, 880, 881, 882, 1369, 1404, 1554, 1556, 1608, 1610, 1698, 1700, 1763, 1765, 1884, 1886, 1951, 1953, 1986, 1988, 2143, 2145, 2412, 2414, 2575, 2577, 2597, 2599, 2689, 2867, 2907, 2911, 2928, 2951, 2952, 2959, 2961, 3020, 3067, 3096, 3103, 3104, 3106, 3110, 3114, 3119, 3120, 3122, 3143, 3146, 3154, 3155, 3156, 3158, 3159, 3162, 3163, 3167, 3190, 3191, 3195, 3198, 3200, 3259, 3271, 3330, 3335, 3342, 3343, 3345, 3385, 3387, 3470, 3472, 3528, 3529, 3530, 3531, 3532, 3534, 3536, 3543, 3545, 3615, 3617, 3718, 3720, 3720, 3721, 3722, 3723, 3724, 3730, 3736, 3737, 3740, 3742, 3745, 3748, 3749, 3756, 3759, 3798, 3821, 3823, 3881, 3925, 3931, 3933, 4148, 4150, 4248, 4250, 4301, 4303, 4574, 4576, 4809, 4811, 4848, 4849, 4856, 4857, 4861, 4871, 4872, 4885, 4887, 4995, 4997, 5011, 5061, 5063, 5104, 5106, 5277, 5279, 5601, 5662, 5663, 5664, 5668, 5669, 5711, 5713, 5751, 5753, 5793, 5795, 5866, 5868, 5924, 5926, 6045, 6047, 6062, 6106, 6107, 6245, 6247, 6437, 6439, 6468, 6470, 6517, 6519, 6560, 6562, 6601, 6603, 6689, 6691, 6708, 6874, 6876, 6962, 6964, 7035, 7037, 7071, 7073, 7105, 7107, 7188, 7190, 7253, 7255, 7291, 7293, 7500, 7502, 7523, 7525, 7564, 7566, 7671, 7673, 7713, 7715, 7731, 7733, 7797, 7799, 7834, 7836, 7858, 7860, 7888, 7890, 7998, 8000, 8026, 8028, 8061, 8098, 8100, 8139, 8141, 8180, 8182, 8211, 8213, 8299, 8301, 8347, 8349, 8658, 8660, 8702, 8704, 8779, 8781, 8818, 8820, 8888, 8890, 8957, 8959, 9187, 9189, 9246, 9248, 9318, 9320, 9350, 9352, 9511, 9513, 9548, 9550, 9572, 9574, 9585, 9609, 9610, 9638, 9640, 9770, 9772, 9870, 9872, 9901, 9903, 10008, 10010, 10057, 10059, 10102, 10104, 10166, 10168, 10204, 10206, 10242, 10244, 10358, 10360, 10488, 10490, 10610, 10612, 10740, 10742, 10800, 10802, 11298, 11300, 11362, 11364, 11446, 11448, 11545, 11547, 11602, 11604, 11614, 11615, 11616, 11617, 11618, 11619, 11620, 11621, 11624, 11625, 11626, 11627, 11732, 11734, 11814, 11816, 11867, 11869, 11949, 11951, 11998, 12000, 12049, 12051, 12177, 12179, 12236, 12238, 12268, 12270, 12316, 12318, 12385, 12387, 12484, 12486, 12524, 12526, 12544, 12546, 12627, 12629, 12660, 12662, 12726, 12728, 12808, 12810, 12844, 12846, 12877, 12879, 12940, 12942, 13004, 13006, 13066, 13068, 13117, 13119, 13121, 13122, 13123, 13125, 13147, 13149, 13177, 13179, 13233, 13235, 13286, 13288, 13365, 13367, 13409, 13411, 13536, 13538, 13741, 13743, 13799, 13808, 13810, 13879, 13881, 13929, 13931, 14079, 14081, 14120, 14122, 14209, 14211, 14211, 14212, 14213, 14215, 14216, 14218, 14222]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"D:\\iiitd\\sem_1\\ML\\Project\\output_2.csv\")\n",
    "df.head()\n",
    "arr1 = df[\"SHOT_INDEX\"].tolist()\n",
    "# print(len(arr1))\n",
    "print(arr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avengers_file_path = \"D:/iiitd/sem_1/ML/Project/VideoCompressionDataset/AvengersEndgme.mkv\"\n",
    "compressed_dir_path = \"D:/iiitd/sem_1/ML/Project/compressed_data\"\n",
    "frame_dir = \"D:\\iiitd\\sem_1\\ML\\Project\\AvengerFrames\"\n",
    "os.makedirs(compressed_dir_path, exist_ok=True)\n",
    "\n",
    "# k = 0\n",
    "for i in arr1:\n",
    "    # if k == 1:\n",
    "    #     break\n",
    "    frame_path = os.path.join(frame_dir, f\"frame_{i:04d}.jpg\")\n",
    "    image = io.imread(frame_path)\n",
    "    io.imsave(os.path.join(compressed_dir_path, f\"{i}.jpg\"), get_frame(image))\n",
    "    # k += 1\n",
    "\n",
    "# cap = cv2.VideoCapture(avengers_file_path)\n",
    "# i = 0\n",
    "# frame_count = 0\n",
    "\n",
    "# if not cap.isOpened():\n",
    "#     print(\"Error: Could not open the video file.\")\n",
    "#     exit()\n",
    "# else:\n",
    "#     while True:\n",
    "#         ret, frame = cap.read()\n",
    "\n",
    "#         if not ret:\n",
    "#             break\n",
    "#         frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#         frame_count += 1\n",
    "#         if(i >= len(arr1)):\n",
    "#             break\n",
    "        \n",
    "#         if frame_count == arr1[i]:\n",
    "#             # cv2.imwrite(os.path.join(compressed_dir_path, f\"{arr[i]}.jpg\"), get_frame(frame))\n",
    "#             io.imsave(os.path.join(compressed_dir_path, f\"{arr1[i]}.jpg\"), get_frame(frame))\n",
    "#             i += 1\n",
    "# cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# clusters_path = \"D:/iiitd/sem_1/ML/Project/bw_data/clusters\"\n",
    "# labels_path = \"D:/iiitd/sem_1/ML/Project/bw_data/labels\"\n",
    "\n",
    "# x = os.listdir(clusters_path)\n",
    "# y = os.listdir(labels_path)\n",
    "# x.sort()\n",
    "# y.sort()\n",
    "# print(x)\n",
    "# print(y)\n",
    "\n",
    "output_path = \"decompressed_avg_video.mp4\"\n",
    "\n",
    "# img = cv2.imread(os.path.join(labels_path, y[0]))\n",
    "# height, width = img.shape\n",
    "r = 1608\n",
    "c = 3840\n",
    "\n",
    "fps = 24\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video = cv2.VideoWriter(output_path, fourcc, fps, (c, r))\n",
    "\n",
    "arr = arr1.copy()\n",
    "# print(arr)\n",
    "arr.append(14228)\n",
    "for i in range(len(arr) - 1):\n",
    "    frame_path = os.path.join(\"D:\\iiitd\\sem_1\\ML\\Project\\compressed_data\", f\"{arr[i]}.jpg\")\n",
    "    img = cv2.imread(frame_path)\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "#     io.imshow(img)\n",
    "#     print(img.shape)\n",
    "    for j in range(arr[i], arr[i + 1]):\n",
    "        video.write(img)\n",
    "# (1608, 3840, 3)\n",
    "video.release()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
